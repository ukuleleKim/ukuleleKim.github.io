<!DOCTYPE html>
<html lang="en"><head><title>ollama와 Open-WebUI 로컬 배포</title><meta charset="utf-8"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto Sans KR&amp;family=Noto Sans KR:wght@400;700&amp;family=Noto Sans KR:ital,wght@0,400;0,600;1,400;1,600&amp;display=swap"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="google-site-verification" content="_y2e8NijEw1pWVSTaAheBdoMwryFwNuDVM99SI0K7aU"/><meta property="og:title" content="ollama와 Open-WebUI 로컬 배포"/><meta property="og:description" content="ollama와 Open-WebUI LLM을 활용한 서비스가 다양하게 출시되는 요즘, 로컬에서 LLM을 사용할 수 있도록 도와주는 ollama이라는 툴에 관심이 생겼습니다. 오픈 LLM 모델의 GGUF 파일이 있다면 ollama를 이용해 로컬 환경에서 LLM과 상호작용이 가능한데요."/><meta property="og:image" content="https://guide-to-devops.github.io/static/og-image.png"/><meta property="og:width" content="1200"/><meta property="og:height" content="675"/><link rel="icon" href="../static/icon.png"/><meta name="description" content="ollama와 Open-WebUI LLM을 활용한 서비스가 다양하게 출시되는 요즘, 로컬에서 LLM을 사용할 수 있도록 도와주는 ollama이라는 툴에 관심이 생겼습니다. 오픈 LLM 모델의 GGUF 파일이 있다면 ollama를 이용해 로컬 환경에서 LLM과 상호작용이 가능한데요."/><meta name="generator" content="Quartz"/><link href="../index.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css" rel="stylesheet" type="text/css" spa-preserve/><script src="../prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch("../static/contentIndex.json").then(data => data.json())</script></head><body data-slug="blog/ollama와-Open-WebUI-로컬-배포"><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h1 class="page-title"><a href="..">Guide to DevOps</a></h1><div class="spacer mobile-only"></div><div class="search"><div id="search-icon"><p>Search</p><div></div><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search</title><desc id="desc">Search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></div><div id="search-container"><div id="search-space"><input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div id="search-layout" data-preview="true"></div></div></div></div><div class="darkmode"><input class="toggle" id="darkmode-toggle" type="checkbox" tabindex="-1"/><label id="toggle-label-light" for="darkmode-toggle" tabindex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35" xml:space="preserve"><title>Dark mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg></label><label id="toggle-label-dark" for="darkmode-toggle" tabindex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background:new 0 0 100 100" xml:space="preserve"><title>Light mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></label></div><div class="recent-notes desktop-only"><h3>Recent Notes</h3><ul class="recent-ul"><li class="recent-li"><div class="section"><div class="desc"><h3><a href="../blog/2024-우아콘-참여-후기---2" class="internal">[2024 우아콘 후기] 프롬프트 엔지니어링, 클라우드 관리 및 컴플라이언스 관련 세션</a></h3></div><p class="meta">Oct 31, 2024</p></div></li><li class="recent-li"><div class="section"><div class="desc"><h3><a href="../blog/2024-우아콘-참여-후기---1" class="internal">[2024 우아콘 후기] AI 데이터 분석가 '물어보새' 소개 및 실시간 추천 검색어 모델링 사례 공유</a></h3></div><p class="meta">Oct 30, 2024</p></div></li><li class="recent-li"><div class="section"><div class="desc"><h3><a href="../blog/Kubernetes-컨테이너-디자인-패턴" class="internal">Kubernetes 컨테이너 디자인 패턴 소개</a></h3></div><p class="meta">Oct 27, 2024</p></div></li><li class="recent-li"><div class="section"><div class="desc"><h3><a href="../blog/CNCF에서-졸업한-KubeEdge-프로젝트-소개" class="internal">최근 CNCF에서 졸업한 KubeEdge 프로젝트란?</a></h3></div><p class="meta">Oct 20, 2024</p></div></li><li class="recent-li"><div class="section"><div class="desc"><h3><a href="../blog/KCNA와-KCSA-자격증-취득-후기" class="internal">KCNA와 KCSA 자격증 취득 후기 및 핵심 키워드</a></h3></div><p class="meta">Oct 13, 2024</p></div></li></ul><p><a href="../blog">See 35 more →</a></p></div></div><div class="center"><div class="page-header"><div class="popover-hint"><nav class="breadcrumb-container" aria-label="breadcrumbs"><div class="breadcrumb-element"><a href="../">Home</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../blog/">blog</a><p> ❯ </p></div><div class="breadcrumb-element"><a href>ollama와 Open-WebUI 로컬 배포</a></div></nav><h1 class="article-title">ollama와 Open-WebUI 로컬 배포</h1><p show-comma="true" class="content-meta"><span>May 20, 2024</span><span>7 min read</span></p><ul class="tags"><li><a href="../tags/Docker" class="internal tag-link">Docker</a></li><li><a href="../tags/Ollama" class="internal tag-link">Ollama</a></li></ul></div></div><article class="popover-hint"><h2 id="ollama와-open-webui">ollama와 Open-WebUI<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#ollama와-open-webui" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>LLM을 활용한 서비스가 다양하게 출시되는 요즘, 로컬에서 LLM을 사용할 수 있도록 도와주는 <strong>ollama</strong>이라는 툴에 관심이 생겼습니다.</p>
<p>오픈 LLM 모델의 <code>GGUF</code> 파일이 있다면 <strong>ollama</strong>를 이용해 로컬 환경에서 LLM과 상호작용이 가능한데요.</p>
<p>로컬 LLM은 개인 정보 유출 위험이 적고 비용 발생도 없다는 장점이 있습니다.</p>
<p>그래서 제 노트북의 로컬 환경에 직접 <strong>ollama</strong>를 실행시킨 다음, 공개된 LLM 모델을 가져와 테스트를 진행해봤습니다.</p>
<p>테스트를 진행한 노트북 사양은 아래와 같습니다.</p>
<ul>
<li>CPU: AMD Ryzen 7 4800H with Radeon Graphics 2.90 GHz</li>
<li>RAM: 32 GB</li>
</ul>
<p>CLI 환경에서 동작하는 <strong>ollama</strong>를 보다 쉽게 사용하기 위해, <strong>Open-WebUI</strong>라는 툴을 함께 사용했는데요.</p>
<p><strong>Open-WebUI</strong>는 Chat GPT와 유사한 UI를 가지고 있고, 호스트에 실행 중인 ollama와 연동되어 웹 브라우저상에서 LLM에 질문을 하거나 다양한 LLM 관련 설정도 가능합니다.</p>
<h2 id="docker-compose를-활용하여-로컬-배포">Docker Compose를 활용하여 로컬 배포<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#docker-compose를-활용하여-로컬-배포" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>ollama와 Open-WebUI 로컬 배포에 대해 조사해보니 모두 로컬에 직접 설치하는 글이 대부분이었지만, 각 툴이 호스트 환경으로부터 독립되어야 일관된 기능이 보장될 수 있으므로 우리는 <strong>Container 환경에서 실행</strong>해보도록 하겠습니다.</p>
<p>다행히 <a href="https://github.com/ollama/ollama?tab=readme-ov-file#docker" class="external">ollama<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>와 <a href="https://github.com/open-webui/open-webui?tab=readme-ov-file#quick-start-with-docker-" class="external">Open-WebUI<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> 모두 공식 <strong>Container Image</strong>가 공개되어 있어서 Docker로 실행하는 데엔 어려움이 없겠는데요.</p>
<p>하지만 로컬 LLM을 사용하고 종료할 때마다 이 툴들의 Container Image를 실행하고 다시 종료하려면 손이 많이 갈 것 같습니다.</p>
<p>그래서 여러 Container를 한 번에 배포할 수 있는 <strong>Docker Compose</strong>를 활용하도록 하겠습니다.</p>
<p><strong>Docker Compose</strong>는 <strong>한 개 이상의 Container를 항상 동일한 옵션과 조건으로 한 번에 실행</strong>할 수 있도록 도와주는 기능입니다. Container 실행에 필요한 각종 정보를 <code>compose.yaml</code>이라는 파일에 정의해두었다가, <code>docker compose</code> 명령어를 실행하면 yaml 파일에 정의된 Container들이 실행되는 방식입니다.</p>
<h2 id="배포-과정">배포 과정<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#배포-과정" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>먼저 아래와 같이 Docker Compose 파일을 정의합니다.</p>
<figure data-rehype-pretty-code-figure><pre style="--shiki-light:#e1e4e8;--shiki-dark:#e1e4e8;--shiki-light-bg:#24292e;--shiki-dark-bg:#24292e;" tabindex="0" data-language="yaml:compose.yaml" data-theme="github-dark github-dark"><code data-language="yaml:compose.yaml" data-theme="github-dark github-dark" style="display:grid;"><span data-line><span>services:</span></span>
<span data-line><span>  openWebUI:</span></span>
<span data-line><span>    image: ghcr.io/open-webui/open-webui:main</span></span>
<span data-line><span>    restart: always</span></span>
<span data-line><span>    ports:</span></span>
<span data-line><span>      - &quot;3000:8080&quot;</span></span>
<span data-line><span>    extra_hosts:</span></span>
<span data-line><span>      - &quot;host.docker.internal:host-gateway&quot;</span></span>
<span data-line><span>    volumes:</span></span>
<span data-line><span>      - open-webui-local:/app/backend/data</span></span>
<span data-line> </span>
<span data-line><span>  ollama:</span></span>
<span data-line><span>    image: ollama/ollama:0.1.34</span></span>
<span data-line><span>    ports:</span></span>
<span data-line><span>      - &quot;11434:11434&quot;</span></span>
<span data-line><span>    volumes:</span></span>
<span data-line><span>      - ollama-local:/root/.ollama</span></span>
<span data-line> </span>
<span data-line><span>volumes:</span></span>
<span data-line><span>  ollama-local:</span></span>
<span data-line><span>    external: true</span></span>
<span data-line><span>  open-webui-local:</span></span>
<span data-line><span>    external: true</span></span></code></pre></figure>
<p>다음은 <strong>Docker Volume</strong> 생성입니다. <strong>Volume</strong>은 Container 동작 중에 생성/수정되는 데이터를 저장하는 공간인데요.
위 <code>compose.yaml</code>에서 정의한 바와 같이, <code>ollama-local</code>(ollama의 데이터 저장)와 <code>open-webui-local</code>(Open-WehUI의 데이터 저장)라는 이름의 Docker volume을 생성하기 위해 터미널에서 아래 명령어를 실행합니다.</p>
<ul>
<li><code>docker volume create ollama-local</code></li>
<li><code>docker volume create open-webui-local</code></li>
</ul>
<p>이제 <code>docker compose</code> 명령어로 두 개의 Container를 로컬에 배포해볼 건데요. 그 전에 <code>compose.yaml</code> 파일이 정상적으로 실행되는지 확인하기 위해 아래 명령어로 <strong>dry run</strong>을 해보겠습니다. (<strong>dry-run</strong>은 어떤 명령어가 예상대로 동작하는지 모의 실행하는 것을 말합니다. 해당 명령어가 실제로 실행되는 것은 아닙니다.)</p>
<ul>
<li><code>docker compose --dry-run up -d</code> (<strong>compose.yaml 파일이 존재하는 경로에서 실행</strong>)
<img src="https://i.imgur.com/ulTBKLM.png" alt/></li>
</ul>
<p>dry run이 잘 실행되는 것을 확인했으니 이제 아래 명령어를 실행하여 실제로 로컬 배포를 진행해보겠습니다.</p>
<ul>
<li><code>docker compose up -d</code> (<strong>compose.yaml 파일이 존재하는 경로에서 실행</strong>)
<img src="https://i.imgur.com/EqpwaFJ.png" alt/></li>
</ul>
<p>각 Container가 정상 실행되었다는 메시지를 확인 후, <code>compose.yaml</code>에서 정의한 <strong>Open-WebUI</strong>의 <code>Port</code> 번호를 참고하여 웹 브라우저에서 localhost로 접속합니다. (본 예제에서 <strong>Open-WebUI</strong> 경로: <a href="http://localhost:3000" class="external">http://localhost:3000<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>)
<img src="https://i.imgur.com/pfrk31E.png" alt/></p>
<p>웹 브라우저로 접속한 Open-WebUI 창에서 <code>Sign up</code> 버튼을 눌러 계정을 새로 만들고 접속합니다. (이렇게 만든 계정은 우리가 이전에 생성한 <strong>Open-WebUI</strong>의 <strong>Docker Volume</strong>에 저장되므로 <code>Sign up</code>은 최초 한 번만 필요하며, 이후엔 계정으로 로그인하면 됩니다.)
<img src="https://i.imgur.com/6PxtQBf.png" alt/></p>
<p>아직 <strong>ollama</strong>에서 사용할 LLM 모델이 없으므로, <strong>Open-WebUI</strong>의 오른쪽 상단의 <code>톱니바퀴 버튼</code>을 누른 뒤 <code>models</code> 메뉴 내 <code>Pull a model from Ollama.com</code> 옵션 입력창에 원하는 LLM 모델의 태그를 입력합니다. (본 예제에서는 <code>llama3:8b</code>를 가져왔습니다. ollama에서 제공하는 LLM 목록은 <a href="https://ollama.com/library" class="external">여기<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>서 확인 가능합니다.)
<img src="https://i.imgur.com/0dHquNS.png" alt/></p>
<p>LLM 모델 다운로드가 완료되면 홈 화면의 왼쪽 상단에서 다운로드한 모델 선택이 가능하고, 이후 Chat을 진행할 수 있습니다.
<img src="https://i.imgur.com/uhkaBTb.png" alt/>
<img src="https://i.imgur.com/Bjzi4rs.png" alt/></p>
<h2 id="로컬-배포한-container-관리">로컬 배포한 Container 관리<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#로컬-배포한-container-관리" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>만약 Docker Compose로 로컬 배포한 <strong>ollama</strong>와 <strong>Open-WebUI</strong> Container를 종료하고 싶다면 아래 명령어를 실행합니다.</p>
<ul>
<li><code>docker compose down</code> (<strong>compose.yaml 파일이 존재하는 경로에서 실행</strong>)</li>
</ul>
<p>추후에 용량 관리를 위해 <strong>ollama</strong>와 <strong>Open-WebUI</strong>가 사용하던 <strong>Volume</strong>을 삭제하고 싶다면 아래 명령어를 실행합니다. (Backup하지 않은 <strong>Volume</strong>은 삭제 후 복구할 수 없습니다.)</p>
<ul>
<li><code>docker volume rm {대상 Volume 이름}</code></li>
</ul>
<h2 id="references">References<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#references" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li><a href="https://github.com/ollama/ollama" class="external">https://github.com/ollama/ollama<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></li>
<li><a href="https://github.com/open-webui/open-webui" class="external">https://github.com/open-webui/open-webui<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></li>
</ul></article></div><div class="right sidebar"><div class="toc desktop-only"><button type="button" id="toc" class><h3>Table of Contents</h3><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="fold"><polyline points="6 9 12 15 18 9"></polyline></svg></button><div id="toc-content"><ul class="overflow"><li class="depth-0"><a href="#ollama와-open-webui" data-for="ollama와-open-webui">ollama와 Open-WebUI</a></li><li class="depth-0"><a href="#docker-compose를-활용하여-로컬-배포" data-for="docker-compose를-활용하여-로컬-배포">Docker Compose를 활용하여 로컬 배포</a></li><li class="depth-0"><a href="#배포-과정" data-for="배포-과정">배포 과정</a></li><li class="depth-0"><a href="#로컬-배포한-container-관리" data-for="로컬-배포한-container-관리">로컬 배포한 Container 관리</a></li><li class="depth-0"><a href="#references" data-for="references">References</a></li></ul></div></div><div class="recent-notes mobile-only"><h3>Recent Notes</h3><ul class="recent-ul"><li class="recent-li"><div class="section"><div class="desc"><h3><a href="../blog/2024-우아콘-참여-후기---2" class="internal">[2024 우아콘 후기] 프롬프트 엔지니어링, 클라우드 관리 및 컴플라이언스 관련 세션</a></h3></div><p class="meta">Oct 31, 2024</p></div></li><li class="recent-li"><div class="section"><div class="desc"><h3><a href="../blog/2024-우아콘-참여-후기---1" class="internal">[2024 우아콘 후기] AI 데이터 분석가 '물어보새' 소개 및 실시간 추천 검색어 모델링 사례 공유</a></h3></div><p class="meta">Oct 30, 2024</p></div></li><li class="recent-li"><div class="section"><div class="desc"><h3><a href="../blog/Kubernetes-컨테이너-디자인-패턴" class="internal">Kubernetes 컨테이너 디자인 패턴 소개</a></h3></div><p class="meta">Oct 27, 2024</p></div></li></ul><p><a href="../blog">See 37 more →</a></p></div><div class="backlinks"><h3>Backlinks</h3><ul class="overflow"><li><a href="../blog/ollama와-crewAI로-로컬-환경에-블로그-포스팅-시스템-구축" class="internal">ollama와 crewAI로 로컬 환경에 블로그 포스팅 시스템 구축</a></li></ul></div></div></div><footer class><hr/><div><h3><p>DevOps 및 클라우드 관련 글을 정기적으로 받아보고 싶다면</p><a href="https://maily.so/newslettertodevops">🔭DevOps 여행을 위한 소식지 구독하기📧</a></h3></div><p>Created with <a href="https://quartz.jzhao.xyz/">Quartz v4.2.3</a> © 2024</p></footer></div></body><script type="application/javascript">function c(){let t=this.parentElement;t.classList.toggle("is-collapsed");let l=t.classList.contains("is-collapsed")?this.scrollHeight:t.scrollHeight;t.style.maxHeight=l+"px";let o=t,e=t.parentElement;for(;e;){if(!e.classList.contains("callout"))return;let n=e.classList.contains("is-collapsed")?e.scrollHeight:e.scrollHeight+o.scrollHeight;e.style.maxHeight=n+"px",o=e,e=e.parentElement}}function i(){let t=document.getElementsByClassName("callout is-collapsible");for(let s of t){let l=s.firstElementChild;if(l){l.addEventListener("click",c),window.addCleanup(()=>l.removeEventListener("click",c));let e=s.classList.contains("is-collapsed")?l.scrollHeight:s.scrollHeight;s.style.maxHeight=e+"px"}}}document.addEventListener("nav",i);window.addEventListener("resize",i);
</script><script type="module">
          let mermaidImport = undefined
          document.addEventListener('nav', async () => {
            if (document.querySelector("code.mermaid")) {
              mermaidImport ||= await import('https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.7.0/mermaid.esm.min.mjs')
              const mermaid = mermaidImport.default
              const darkMode = document.documentElement.getAttribute('saved-theme') === 'dark'
              mermaid.initialize({
                startOnLoad: false,
                securityLevel: 'loose',
                theme: darkMode ? 'dark' : 'default'
              })

              await mermaid.run({
                querySelector: '.mermaid'
              })
            }
          });
          </script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/contrib/copy-tex.min.js" type="application/javascript"></script><script src="../postscript.js" type="module"></script></html>