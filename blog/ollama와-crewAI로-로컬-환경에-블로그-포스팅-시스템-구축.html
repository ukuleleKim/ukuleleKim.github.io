<!DOCTYPE html>
<html lang="en"><head><title>ollama와 crewAI로 로컬 환경에 블로그 포스팅 시스템 구축</title><meta charset="utf-8"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto Sans KR&amp;family=Noto Sans KR:wght@400;700&amp;family=Noto Sans KR:ital,wght@0,400;0,600;1,400;1,600&amp;display=swap"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:title" content="ollama와 crewAI로 로컬 환경에 블로그 포스팅 시스템 구축"/><meta property="og:description" content="🦙🧑‍🤝‍🧑Ollama와 CrewAI Ollama는 로컬 환경에서 LLM을 실행하는 오픈소스 툴입니다. 지난 글에서 Docker로 Ollama와 Open-WebUI라는 툴을 실행해서 웹 브라우저로 로컬 LLM에게 질문을 해보는 튜토리얼을 진행한 적이 있었죠. (관련 블로그 글) 이번엔 Ollama와 CrewAI를 활용해서 로컬 LLM 기반으로 블로그 글을 작성해주는 시스템을 구축해보려합니다."/><meta property="og:image" content="https://guide-to-devops.github.io/static/og-image.png"/><meta property="og:width" content="1200"/><meta property="og:height" content="675"/><link rel="icon" href="../static/icon.png"/><meta name="description" content="🦙🧑‍🤝‍🧑Ollama와 CrewAI Ollama는 로컬 환경에서 LLM을 실행하는 오픈소스 툴입니다. 지난 글에서 Docker로 Ollama와 Open-WebUI라는 툴을 실행해서 웹 브라우저로 로컬 LLM에게 질문을 해보는 튜토리얼을 진행한 적이 있었죠. (관련 블로그 글) 이번엔 Ollama와 CrewAI를 활용해서 로컬 LLM 기반으로 블로그 글을 작성해주는 시스템을 구축해보려합니다."/><meta name="generator" content="Quartz"/><link href="../index.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css" rel="stylesheet" type="text/css" spa-preserve/><script src="../prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch("../static/contentIndex.json").then(data => data.json())</script></head><body data-slug="blog/ollama와-crewAI로-로컬-환경에-블로그-포스팅-시스템-구축"><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h1 class="page-title"><a href="..">Guide to DevOps</a></h1><div class="spacer mobile-only"></div><div class="search"><div id="search-icon"><p>Search</p><div></div><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search</title><desc id="desc">Search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></div><div id="search-container"><div id="search-space"><input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div id="search-layout" data-preview="true"></div></div></div></div><div class="darkmode"><input class="toggle" id="darkmode-toggle" type="checkbox" tabindex="-1"/><label id="toggle-label-light" for="darkmode-toggle" tabindex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35" xml:space="preserve"><title>Dark mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg></label><label id="toggle-label-dark" for="darkmode-toggle" tabindex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background:new 0 0 100 100" xml:space="preserve"><title>Light mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></label></div><div class="recent-notes desktop-only"><h3>Recent Notes</h3><ul class="recent-ul"><li class="recent-li"><div class="section"><div class="desc"><h3><a href="../blog/Infrastructure-as-Code-(IaC)-알아보기" class="internal">Infrastructure as Code (IaC) 알아보기</a></h3></div><p class="meta">Aug 18, 2024</p></div></li><li class="recent-li"><div class="section"><div class="desc"><h3><a href="../blog/LLMOps를-위한-오픈소스-플랫폼-Dify" class="internal">LLMOps를 위한 오픈소스 플랫폼 Dify 알아보기</a></h3></div><p class="meta">Aug 11, 2024</p></div></li><li class="recent-li"><div class="section"><div class="desc"><h3><a href="../blog/플랫폼-엔지니어링이란" class="internal">플랫폼 엔지니어링이란?</a></h3></div><p class="meta">Aug 04, 2024</p></div></li><li class="recent-li"><div class="section"><div class="desc"><h3><a href="../blog/kubectl-플러그인-매니저-krew-사용해보기" class="internal">kubectl 플러그인 매니저 krew 사용해보기</a></h3></div><p class="meta">Jul 28, 2024</p></div></li><li class="recent-li"><div class="section"><div class="desc"><h3><a href="../blog/Liveness,-Readiness,-Startup-Probe-소개-및-비교" class="internal">Liveness, Readiness, Startup Probe 비교</a></h3></div><p class="meta">Jul 09, 2024</p></div></li></ul><p><a href="../blog">See 24 more →</a></p></div></div><div class="center"><div class="page-header"><div class="popover-hint"><nav class="breadcrumb-container" aria-label="breadcrumbs"><div class="breadcrumb-element"><a href="../">Home</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../blog/">blog</a><p> ❯ </p></div><div class="breadcrumb-element"><a href>ollama와 crewAI로 로컬 환경에 블로그 포스팅 시스템 구축</a></div></nav><h1 class="article-title">ollama와 crewAI로 로컬 환경에 블로그 포스팅 시스템 구축</h1><p show-comma="true" class="content-meta"><span>Jun 23, 2024</span><span>14 min read</span></p><ul class="tags"><li><a href="../tags/Ollama" class="internal tag-link">Ollama</a></li><li><a href="../tags/CrewAI" class="internal tag-link">CrewAI</a></li></ul></div></div><article class="popover-hint"><h2 id="ollama와-crewai">🦙🧑‍🤝‍🧑Ollama와 CrewAI<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#ollama와-crewai" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p><strong>Ollama</strong>는 로컬 환경에서 LLM을 실행하는 오픈소스 툴입니다. 지난 글에서 Docker로 Ollama와 Open-WebUI라는 툴을 실행해서  웹 브라우저로 로컬 LLM에게 질문을 해보는 튜토리얼을 진행한 적이 있었죠. (<a href="../blog/ollama와-Open-WebUI-로컬-배포" class="internal alias" data-slug="blog/ollama와-Open-WebUI-로컬-배포">관련 블로그 글</a>)</p>
<p>이번엔 <strong>Ollama와 CrewAI</strong>를 활용해서 로컬 LLM 기반으로 블로그 글을 작성해주는 시스템을 구축해보려합니다.</p>
<p>Ollama만으로도 충분히 블로그 글을 자동으로 작성할 수 있지 않냐고요? 물론 Ollama로 실행한 LLM에게 부탁해도 글을 써줍니다. 하지만 <strong>CrewAI</strong>라는 툴을 사용하면, 각자의 <strong>역할과 목표</strong>를 가지고 있는 여러 <strong>LLM 기반 작업자</strong>(<strong>에이전트</strong>)가 <strong>일련의 프로세스</strong>를 거쳐 더욱 <strong>체계적</strong>으로 글을 써줄 수 있거든요.</p>
<p><img src="https://i.imgur.com/2Z9qGz2.png" alt/></p>
<p>방금 이야기한 블로그 글 작성 시스템을 예로 들면서 알아보겠습니다.
DevOps 관련 블로그 글을 쓸 때는 보통 아래와 같은 프로세스로 진행이 될 텐데요.</p>
<ol>
<li><strong>인터넷 자료 조사</strong></li>
<li><strong>조사한 내용을 토대로 글쓰기</strong></li>
<li><strong>작성한 글에 오탈자는 없는지 검수하기</strong></li>
</ol>
<p>이러한 각 과정을 수행하는 에이전트들을 둬서 서로 상호작용하며 작업을 수행하도록 시스템을 만드는 것이 <strong>CrewAI의 역할</strong>입니다.</p>
<p>게다가 <strong>CrewAI</strong>는 <strong>파이썬 기반으로 개발되었고 직관적인 명령어들을 사용</strong>하기 때문에, <strong>쉽고 빠르게 여러 에이전트로 구성된(Multi-Agent) 작업 수행 시스템을 구축</strong>할 수 있다는 장점도 있습니다.</p>
<p><strong>CrewAI</strong>의 <strong>에이전트는 역할, 목표, 배경으로 정의</strong>하는데요. 각 에이전트가 작업을 수행할 때 자신은 어떤 배경을 가지고 있고, 어떤 목표를 수행하는지 등을 미리 알려주는 거죠.</p>
<p><img src="https://i.imgur.com/dJVeV9A.png" alt/></p>
<p>위의 블로그 글 작성 시스템으로 다시 돌아와서, 위에서 언급한 프로세스의 3가지 작업을 담당하는 <strong>CrewAI 에이전트들을 아래처럼 정의</strong>해보겠습니다.</p>
<ul>
<li><strong>인터넷 자료 조사</strong>
<ul>
<li>역할: Researcher</li>
<li>목표: 최신 DevOps 관련 토픽 조사</li>
<li>배경: IT 대기업에서 근무 중인 세계적인 Researcher</li>
</ul>
</li>
<li><strong>글쓰기</strong>
<ul>
<li>역할: Writer</li>
<li>목표: DevOps 관련 블로그 글 작성</li>
<li>배경: IT 관련 글 작성에 특화된 최고의 Technical Writer</li>
</ul>
</li>
<li><strong>검수하기</strong>
<ul>
<li>역할: Proofreader</li>
<li>목표: 기술 블로그 글 검수</li>
<li>배경: IT 분야에 특화된 유명 Proofreader</li>
</ul>
</li>
</ul>
<p>그리고 각 수행되어야 하는 작업도 아래와 같이 정의할 수 있습니다.</p>
<ul>
<li><strong>최신 DevOps 관련 뉴스 조사</strong>
<ul>
<li>담당 에이전트: Researcher</li>
<li>출력물 설명: 약 3문단 분량의 최신 DevOps 관련 리포트</li>
</ul>
</li>
<li><strong>조사 리포트를 기반으로 DevOps 관련 블로그 글 한 편 작성</strong>
<ul>
<li>담당 에이전트: Writer</li>
<li>출력물 설명: 약 4문단 분량의 Markdown 형식 DevOps 관련 블로그 글</li>
</ul>
</li>
<li><strong>제공된 블로그 글을 보다 자연스럽게 검수</strong>
<ul>
<li>담당 에이전트: Proofreader</li>
<li>출력물 설명: 약 4문단 분량의 Markdown 형식 DevOps 관련 블로그 글</li>
</ul>
</li>
</ul>
<blockquote>
<p>웹 접근 관련 유의사항
로컬 LLM을 사용하는 상황에서 웹 접근이 필요한 Researcher 같은 경우엔 Google search API 서비스 등을 별도로 이용해야 합니다.</p>
<p>그래서 이번 실습에선 카드 등록 없이 이메일 등록으로 최대 2,500회 Google Search 쿼리가 가능한 <a href="https://serper.dev/" class="external">Serper<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> 서비스를 이용했습니다.</p>
</blockquote>
<h2 id="️ollama와-crewai로-블로그-글-작성-시스템-구축하기">🖥️Ollama와 CrewAI로 블로그 글 작성 시스템 구축하기<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#️ollama와-crewai로-블로그-글-작성-시스템-구축하기" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>이제 <strong>로컬에서 직접 Ollama와 CrewAI를 실행해서 블로그 글 작성 시스템을 구축</strong>해보도록 하겠습니다. 각 툴은 <strong>Docker로 로컬에 배포</strong>합니다.</p>
<p>이번 실습에선 Ollama의 llama3(8b) 모델을 활용할 예정인데요. 그럴려면 먼저 <strong>Ollama를 이용해서 llama3 모델을 로컬에 가져와야겠죠.</strong></p>
<p>Ollama의 모델이 저장될 공간인 <strong>Docker volume</strong>을 먼저 아래 명령어로 생성합니다.</p>
<figure data-rehype-pretty-code-figure><pre style="--shiki-light:#e1e4e8;--shiki-dark:#e1e4e8;--shiki-light-bg:#24292e;--shiki-dark-bg:#24292e;" tabindex="0" data-language="Shell" data-theme="github-dark github-dark"><code data-language="Shell" data-theme="github-dark github-dark" style="display:grid;"><span data-line><span>docker volume create ollama-local</span></span></code></pre></figure>
<p>Docker volume을 생성했다면 이제 <code>compose.yaml</code>라는 이름의  Docker compose 파일을 생성하겠습니다. <strong>Docker compose는 여러 Docker 컨테이너의 배포 설정을 쉽게 관리하고 실행할 수 있도록 정의하는 파일</strong>인데요. 지금은 우선 Ollama에 대해서만 정의해보겠습니다.</p>
<figure data-rehype-pretty-code-figure><figcaption data-rehype-pretty-code-title data-language="yaml" data-theme="github-dark github-dark">compose.yaml</figcaption><pre style="--shiki-light:#e1e4e8;--shiki-dark:#e1e4e8;--shiki-light-bg:#24292e;--shiki-dark-bg:#24292e;" tabindex="0" data-language="yaml" data-theme="github-dark github-dark"><code data-language="yaml" data-theme="github-dark github-dark" style="display:grid;"><span data-line><span style="--shiki-light:#85E89D;--shiki-dark:#85E89D;">services</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">:</span></span>
<span data-line><span style="--shiki-light:#85E89D;--shiki-dark:#85E89D;">  ollama</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">:</span></span>
<span data-line><span style="--shiki-light:#85E89D;--shiki-dark:#85E89D;">    image</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;">ollama/ollama:0.1.34</span></span>
<span data-line><span style="--shiki-light:#85E89D;--shiki-dark:#85E89D;">    container_name</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;">ollama</span></span>
<span data-line><span style="--shiki-light:#85E89D;--shiki-dark:#85E89D;">    ports</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">:</span></span>
<span data-line><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">      - </span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;">&quot;11434:11434&quot;</span></span>
<span data-line><span style="--shiki-light:#85E89D;--shiki-dark:#85E89D;">    volumes</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">:</span></span>
<span data-line><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">      - </span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;">ollama-local:/root/.ollama</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> #LLM이 저장될 Volume 지정</span></span>
<span data-line><span style="--shiki-light:#85E89D;--shiki-dark:#85E89D;">volumes</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">:</span></span>
<span data-line><span style="--shiki-light:#85E89D;--shiki-dark:#85E89D;">  ollama-local</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">:</span></span>
<span data-line><span style="--shiki-light:#85E89D;--shiki-dark:#85E89D;">    external</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#79B8FF;--shiki-dark:#79B8FF;">true</span></span></code></pre></figure>
<p><code>compose.yaml</code> 작성이 끝나면 해당 파일이 있는 경로의 터미널에서 아래 명령어로 Docker compose를 실행하겠습니다. 지금은 <strong>Docker compose 파일에 정의되어 있는 Ollama만 실행</strong>되겠죠?</p>
<figure data-rehype-pretty-code-figure><pre style="--shiki-light:#e1e4e8;--shiki-dark:#e1e4e8;--shiki-light-bg:#24292e;--shiki-dark-bg:#24292e;" tabindex="0" data-language="Shell" data-theme="github-dark github-dark"><code data-language="Shell" data-theme="github-dark github-dark" style="display:grid;"><span data-line><span>docker compose up -d</span></span></code></pre></figure>
<p>Ollama가 정상 실행되었다면 터미널에 아래처럼 표시가 될 겁니다.
<img src="https://i.imgur.com/AgtB2Py.png" alt/></p>
<p>이제 실행된 Ollama 컨테이너에 접속해서 우리가 사용할 llama3 LLM을 가져오겠습니다.</p>
<p>먼저 아래 터미널 명령어로 <strong>Ollama 컨테이너에 접속</strong>합니다.</p>
<figure data-rehype-pretty-code-figure><pre style="--shiki-light:#e1e4e8;--shiki-dark:#e1e4e8;--shiki-light-bg:#24292e;--shiki-dark-bg:#24292e;" tabindex="0" data-language="Shell" data-theme="github-dark github-dark"><code data-language="Shell" data-theme="github-dark github-dark" style="display:grid;"><span data-line><span>docker exec -it ollama bash</span></span></code></pre></figure>
<p>접속한 터미널은 아래와 유사한 모습일 겁니다.
<img src="https://i.imgur.com/1uGgWUa.png" alt/></p>
<p>이 상태에서 아래 Ollama 명령어를 입력해서 공개된 원격 저장소에서 LLM을 가져옵니다.</p>
<figure data-rehype-pretty-code-figure><pre style="--shiki-light:#e1e4e8;--shiki-dark:#e1e4e8;--shiki-light-bg:#24292e;--shiki-dark-bg:#24292e;" tabindex="0" data-language="Shell" data-theme="github-dark github-dark"><code data-language="Shell" data-theme="github-dark github-dark" style="display:grid;"><span data-line><span>ollama pull llama3:8b</span></span></code></pre></figure>
<p>위 명령어를 입력하면 아래처럼 LLM을 가져오는데요. 가져온 LLM은 처음에 생성했던 Docker volume <code>ollama-local</code>에 저장됩니다.
<img src="https://i.imgur.com/tVUljF6.png" alt/></p>
<p><code>compose.yaml</code> 파일에서 Ollama 컨테이너와 <code>ollama-local</code> volume 연동 설정을 넣어두었기 때문에, <code>compose.yaml</code> 파일로 실행하는 Ollama는 llama3:8b LLM을 계속 사용할 수 있게 됩니다.</p>
<p>Ollama로 LLM 설치는 완료되었으니, <code>exit</code> 명령어로 컨테이너에서 나옵니다.</p>
<p>이제 <strong>CrewAI를 Docker로 실행</strong>해볼 건데요. CrewAI는 파이썬 패키지이므로, 우리가 <strong>작성해야 할 파일은 아래와 같이 총 3가지</strong>입니다.</p>
<ul>
<li>CrewAI를 Docker에서 실행하기 위한 Dockerfile(<code>crewai.Dockerfile</code>)</li>
<li>CrewAI 관련 설정과 정의 후 실행하는 Python 스크립트(<code>main-crewai.py</code>)</li>
<li><code>main-crewai.py</code> 실행에 필요한 패키지를 정의한 <code>requirements.txt</code></li>
</ul>
<figure data-rehype-pretty-code-figure><figcaption data-rehype-pretty-code-title data-language="Dockerfile" data-theme="github-dark github-dark">crewai.Dockerfile</figcaption><pre style="--shiki-light:#e1e4e8;--shiki-dark:#e1e4e8;--shiki-light-bg:#24292e;--shiki-dark-bg:#24292e;" tabindex="0" data-language="Dockerfile" data-theme="github-dark github-dark"><code data-language="Dockerfile" data-theme="github-dark github-dark" style="display:grid;"><span data-line><span>FROM python:3.12.4</span></span>
<span data-line> </span>
<span data-line><span>WORKDIR /app</span></span>
<span data-line><span>COPY requirements.txt ./requirements.txt</span></span>
<span data-line><span>RUN pip install -r requirements.txt</span></span>
<span data-line> </span>
<span data-line><span>COPY main-crewai.py ./</span></span>
<span data-line> </span>
<span data-line><span>CMD [ &quot;python3&quot;, &quot;-u&quot;, &quot;main-crewai.py&quot; ]</span></span></code></pre></figure>
<figure data-rehype-pretty-code-figure><figcaption data-rehype-pretty-code-title data-language="python" data-theme="github-dark github-dark">main-crewai.py</figcaption><pre style="--shiki-light:#e1e4e8;--shiki-dark:#e1e4e8;--shiki-light-bg:#24292e;--shiki-dark-bg:#24292e;" tabindex="0" data-language="python" data-theme="github-dark github-dark"><code data-language="python" data-theme="github-dark github-dark" style="display:grid;"><span data-line><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;"> os</span></span>
<span data-line><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;"> crewai </span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;"> Agent, Task, Crew, Process</span></span>
<span data-line><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;"> crewai_tools </span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;"> SerperDevTool</span></span>
<span data-line> </span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 로컬에 실행 중인 ollama에서 원하는 LLM 가져옴. 예제에선 llama3 (파라미터 사이즈 8b) 사용</span></span>
<span data-line><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;"> langchain.llms </span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;"> Ollama</span></span>
<span data-line><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">ollama_model </span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;"> Ollama(</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">    base_url</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;">'http://ollama:11434'</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">,</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">    model</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;">&quot;llama3:8b&quot;</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">)</span></span>
<span data-line> </span>
<span data-line><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">os.environ[</span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;">&quot;OTEL_SDK_DISABLED&quot;</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;"> &quot;true&quot;</span></span>
<span data-line> </span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># researcher Agent가 웹에 접근해서 최신 IT 정보를 찾을 수 있도록 server.dev API 서비스 이용</span></span>
<span data-line><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">os.environ[</span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;">&quot;SERPER_API_KEY&quot;</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;"> &quot;{자신의 serper API key를 넣어주세요}&quot;</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">  # serper.dev API key</span></span>
<span data-line><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">search_tool </span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;"> SerperDevTool()</span></span>
<span data-line> </span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># crewai 패키지로 원하는 Agent의 역할(role)과 목표(goal) 설정</span></span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 최신 DevOps 관련 토픽을 조사하는 Agent 정의</span></span>
<span data-line><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">researcher </span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;"> Agent(</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">    role</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;">'Researcher'</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">,</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">    goal</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;">'Discover a newest and attracting topic about DevOps'</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">,</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">    backstory</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;">&quot;You're world class researcher working on a big IT company&quot;</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">,</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">    verbose</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#79B8FF;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">,</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">    allow_delegation</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#79B8FF;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">,</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">    llm</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">ollama_model,</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">    tools</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">[search_tool]</span></span>
<span data-line><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">)</span></span>
<span data-line> </span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 블로그 글을 작성하는 Agent 정의</span></span>
<span data-line><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">writer </span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;"> Agent(</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">    role</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;">'Writer'</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">,</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">    goal</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;">'Create DevOps blog post'</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">,</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">    backstory</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;">&quot;You're a best technical writer who is specialized on writing IT content&quot;</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">,</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">    verbose</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#79B8FF;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">,</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">    allow_delegation</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#79B8FF;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">,</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">    llm</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">ollama_model</span></span>
<span data-line><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">)</span></span>
<span data-line> </span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 작성된 글을 검수하는 Agent 정의</span></span>
<span data-line><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">proofreader </span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;"> Agent(</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">    role</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;">'Proofreader'</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">,</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">    goal</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;">'Edit and proofread technical article'</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">,</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">    backstory</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;">&quot;You're a famous proofreader who is specialized on IT domain&quot;</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">,</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">    verbose</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#79B8FF;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">,</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">    allow_delegation</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#79B8FF;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">,</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">    llm</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">ollama_model</span></span>
<span data-line><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">)</span></span>
<span data-line> </span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 정의한 Agent들로 수행할 작업(Task) 정의</span></span>
<span data-line><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">research_task </span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;"> Task(</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">    description</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;">'Investigate the latest DevOps news'</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">,</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">    agent</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">researcher,</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">    expected_output</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;"> 'A comprehensive 3 paragraphs long report on the latest and famous DevOps.'</span></span>
<span data-line><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">)</span></span>
<span data-line> </span>
<span data-line><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">writing_task </span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;"> Task(</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">    description</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;">'Write a blog post about DevOps with one topic provided from the researcher'</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">,</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">    agent</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">writer,</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">    expected_output</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;">'A 4 paragraph article about DevOps formatted as markdown.'</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">,    </span></span>
<span data-line><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">)</span></span>
<span data-line> </span>
<span data-line><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">proofreading_task </span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;"> Task(</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">    description</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;">'Proofread the provided blog post to make more natural article'</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">,</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">    agent</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">proofreader,</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">    expected_output</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;">'A 4 paragraph article about DevOps formatted as markdown.'</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">,    </span></span>
<span data-line><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">)</span></span>
<span data-line> </span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 위 Agent와 Task, 작업 프로세스를 정의</span></span>
<span data-line><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">crew </span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;"> Crew(</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">  agents</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">[researcher, writer, proofreader],</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">  tasks</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">[research_task, writing_task, proofreading_task],</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">  llm</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">ollama_model,</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">  verbose</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#79B8FF;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># crew 작업 중에 발생하는 로그의 자세한 정도를 설정 가능.</span></span>
<span data-line><span style="--shiki-light:#FFAB70;--shiki-dark:#FFAB70;">  process</span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">Process.sequential </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Task가 순차적으로 실행될 수 있도록 sequential로 정의.</span></span>
<span data-line><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">)</span></span>
<span data-line> </span>
<span data-line><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 정의한 crew 실행 및 작업 과정에서 발생하는 로그 출력</span></span>
<span data-line><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">result </span><span style="--shiki-light:#F97583;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;"> crew.kickoff()</span></span>
<span data-line><span style="--shiki-light:#79B8FF;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">(result)</span></span></code></pre></figure>
<figure data-rehype-pretty-code-figure><figcaption data-rehype-pretty-code-title data-language="text" data-theme="github-dark github-dark">requirements.txt</figcaption><pre style="--shiki-light:#e1e4e8;--shiki-dark:#e1e4e8;--shiki-light-bg:#24292e;--shiki-dark-bg:#24292e;" tabindex="0" data-language="text" data-theme="github-dark github-dark"><code data-language="text" data-theme="github-dark github-dark" style="display:grid;"><span data-line><span>crewai==0.32.0</span></span>
<span data-line><span>crewai-tools==0.2.6</span></span>
<span data-line><span>langchain==0.1.20</span></span></code></pre></figure>
<p>CrewAI 관련 파일 준비가 끝났다면, 아래 Docker 명령어로 <strong>CrewAI가 실행될 Docker 이미지를 생성</strong>합니다.</p>
<figure data-rehype-pretty-code-figure><pre style="--shiki-light:#e1e4e8;--shiki-dark:#e1e4e8;--shiki-light-bg:#24292e;--shiki-dark-bg:#24292e;" tabindex="0" data-language="Shell" data-theme="github-dark github-dark"><code data-language="Shell" data-theme="github-dark github-dark" style="display:grid;"><span data-line><span>docker build -t my-crewai -f crewai.Dockerfile .</span></span></code></pre></figure>
<p>CrewAI Docker 이미지 빌드가 끝났다면, 위에서 정의했던 <code>compose.yaml</code> 파일을 아래와 같이 최신화합니다.</p>
<figure data-rehype-pretty-code-figure><figcaption data-rehype-pretty-code-title data-language="yaml" data-theme="github-dark github-dark">compose.yaml</figcaption><pre style="--shiki-light:#e1e4e8;--shiki-dark:#e1e4e8;--shiki-light-bg:#24292e;--shiki-dark-bg:#24292e;" tabindex="0" data-language="yaml" data-theme="github-dark github-dark"><code data-language="yaml" data-theme="github-dark github-dark" style="display:grid;"><span data-line><span style="--shiki-light:#85E89D;--shiki-dark:#85E89D;">services</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">:</span></span>
<span data-line><span style="--shiki-light:#85E89D;--shiki-dark:#85E89D;">  ollama</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">:</span></span>
<span data-line><span style="--shiki-light:#85E89D;--shiki-dark:#85E89D;">    image</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;">ollama/ollama:0.1.34</span></span>
<span data-line><span style="--shiki-light:#85E89D;--shiki-dark:#85E89D;">    container_name</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;">ollama</span></span>
<span data-line><span style="--shiki-light:#85E89D;--shiki-dark:#85E89D;">    ports</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">:</span></span>
<span data-line><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">      - </span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;">&quot;11434:11434&quot;</span></span>
<span data-line><span style="--shiki-light:#85E89D;--shiki-dark:#85E89D;">    volumes</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">:</span></span>
<span data-line><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">      - </span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;">ollama-local:/root/.ollama</span></span>
<span data-line><span style="--shiki-light:#85E89D;--shiki-dark:#85E89D;">  crewai</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">:</span></span>
<span data-line><span style="--shiki-light:#85E89D;--shiki-dark:#85E89D;">    image</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;">my-crewai</span></span>
<span data-line><span style="--shiki-light:#85E89D;--shiki-dark:#85E89D;">    container_name</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;">crewai</span></span>
<span data-line><span style="--shiki-light:#85E89D;--shiki-dark:#85E89D;">    depends_on</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">:</span></span>
<span data-line><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">      - </span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;">ollama</span></span>
<span data-line><span style="--shiki-light:#85E89D;--shiki-dark:#85E89D;">    extra_hosts</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">:</span></span>
<span data-line><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">      - </span><span style="--shiki-light:#9ECBFF;--shiki-dark:#9ECBFF;">&quot;telemetry.crewai.com:127.0.0.1&quot;</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> # To avoid 'Connection to telemetry.crewai.com timed out' error when using local LLM</span></span>
<span data-line><span style="--shiki-light:#85E89D;--shiki-dark:#85E89D;">volumes</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">:</span></span>
<span data-line><span style="--shiki-light:#85E89D;--shiki-dark:#85E89D;">  ollama-local</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">:</span></span>
<span data-line><span style="--shiki-light:#85E89D;--shiki-dark:#85E89D;">    external</span><span style="--shiki-light:#E1E4E8;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#79B8FF;--shiki-dark:#79B8FF;">true</span></span></code></pre></figure>
<p>이제 터미널에서 아래 Docker compose 명령어를 입력하면, <strong>CrewAI의 각 에이전트가 작업을 수행하는 과정과 최종 결과물을 터미널에서 확인</strong>할 수 있습니다. (명령어 마지막에 <code>docker compose down</code>을 연결한 것은 CrewAI 작업이 모두 완료되면 <code>Ollama</code>와 <code>CrewAI</code> 컨테이너 모두 정상 종료시키기 위함입니다.)</p>
<figure data-rehype-pretty-code-figure><pre style="--shiki-light:#e1e4e8;--shiki-dark:#e1e4e8;--shiki-light-bg:#24292e;--shiki-dark-bg:#24292e;" tabindex="0" data-language="Shell" data-theme="github-dark github-dark"><code data-language="Shell" data-theme="github-dark github-dark" style="display:grid;"><span data-line><span>docker compose up -d &amp;&amp; docker compose logs crewai -f &amp;&amp; docker compose down</span></span></code></pre></figure>
<h2 id="️crewai의-에이전트들의-작업-과정과-최종-생성-결과물">🗂️CrewAI의 에이전트들의 작업 과정과 최종 생성 결과물<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#️crewai의-에이전트들의-작업-과정과-최종-생성-결과물" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>이렇게 실행한 CrewAI의 로그를 살펴보면, 각 에이전트가 일하는 과정을 로그로 확인할 수 있습니다.
<img src="https://i.imgur.com/4Kbt5ip.png" alt/>
<img src="https://i.imgur.com/Xym7MDk.png" alt/></p>
<p>또한 에이전트가 내놓은 최종 결과물도 확인할 수 있죠.
<img src="https://i.imgur.com/4Y4LN0y.png" alt/></p>
<p>CrewAI의 Researcher 에이전트가 작성한 리포트를 토대로 Writer 에이전트가 블로그 글을 써주는 등, 각 에이전트가 미리 정의된 프로세스대로 상호작용하는 것을 보니 정말 흥미로웠는데요.😄</p>
<p>블로그 글 작성 외에도 CrewAI를 활용해서 어떤 작업 프로세스를 수행할 수 있을지 궁금해지네요.😊</p>
<h2 id="references">References<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#references" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li><a href="https://docs.crewai.com/" class="external">https://docs.crewai.com/<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></li>
<li><a href="https://fossengineer.com/ai-agents-crewai/#building-the-crewai-container" class="external">https://fossengineer.com/ai-agents-crewai/#building-the-crewai-container<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></li>
<li><a href="https://medium.com/the-ai-forum/create-a-blog-writer-multi-agent-system-using-crewai-and-ollama-f47654a5e1cd" class="external"># Create a Blog Writer Multi-Agent System using Crewai and Ollama<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></li>
</ul></article></div><div class="right sidebar"><div class="toc desktop-only"><button type="button" id="toc" class><h3>Table of Contents</h3><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="fold"><polyline points="6 9 12 15 18 9"></polyline></svg></button><div id="toc-content"><ul class="overflow"><li class="depth-0"><a href="#ollama와-crewai" data-for="ollama와-crewai">🦙🧑‍🤝‍🧑Ollama와 CrewAI</a></li><li class="depth-0"><a href="#️ollama와-crewai로-블로그-글-작성-시스템-구축하기" data-for="️ollama와-crewai로-블로그-글-작성-시스템-구축하기">🖥️Ollama와 CrewAI로 블로그 글 작성 시스템 구축하기</a></li><li class="depth-0"><a href="#️crewai의-에이전트들의-작업-과정과-최종-생성-결과물" data-for="️crewai의-에이전트들의-작업-과정과-최종-생성-결과물">🗂️CrewAI의 에이전트들의 작업 과정과 최종 생성 결과물</a></li><li class="depth-0"><a href="#references" data-for="references">References</a></li></ul></div></div><div class="recent-notes mobile-only"><h3>Recent Notes</h3><ul class="recent-ul"><li class="recent-li"><div class="section"><div class="desc"><h3><a href="../blog/Infrastructure-as-Code-(IaC)-알아보기" class="internal">Infrastructure as Code (IaC) 알아보기</a></h3></div><p class="meta">Aug 18, 2024</p></div></li><li class="recent-li"><div class="section"><div class="desc"><h3><a href="../blog/LLMOps를-위한-오픈소스-플랫폼-Dify" class="internal">LLMOps를 위한 오픈소스 플랫폼 Dify 알아보기</a></h3></div><p class="meta">Aug 11, 2024</p></div></li><li class="recent-li"><div class="section"><div class="desc"><h3><a href="../blog/플랫폼-엔지니어링이란" class="internal">플랫폼 엔지니어링이란?</a></h3></div><p class="meta">Aug 04, 2024</p></div></li></ul><p><a href="../blog">See 26 more →</a></p></div><div class="backlinks"><h3>Backlinks</h3><ul class="overflow"><li>No backlinks found</li></ul></div></div></div><footer class><hr/><div><h3><p>DevOps 및 클라우드 관련 글을 정기적으로 받아보고 싶다면</p><a href="https://maily.so/newslettertodevops">🔭DevOps 여행을 위한 소식지 구독하기📧</a></h3></div><p>Created with <a href="https://quartz.jzhao.xyz/">Quartz v4.2.3</a> © 2024</p></footer></div></body><script type="application/javascript">function c(){let t=this.parentElement;t.classList.toggle("is-collapsed");let l=t.classList.contains("is-collapsed")?this.scrollHeight:t.scrollHeight;t.style.maxHeight=l+"px";let o=t,e=t.parentElement;for(;e;){if(!e.classList.contains("callout"))return;let n=e.classList.contains("is-collapsed")?e.scrollHeight:e.scrollHeight+o.scrollHeight;e.style.maxHeight=n+"px",o=e,e=e.parentElement}}function i(){let t=document.getElementsByClassName("callout is-collapsible");for(let s of t){let l=s.firstElementChild;if(l){l.addEventListener("click",c),window.addCleanup(()=>l.removeEventListener("click",c));let e=s.classList.contains("is-collapsed")?l.scrollHeight:s.scrollHeight;s.style.maxHeight=e+"px"}}}document.addEventListener("nav",i);window.addEventListener("resize",i);
</script><script type="module">
          let mermaidImport = undefined
          document.addEventListener('nav', async () => {
            if (document.querySelector("code.mermaid")) {
              mermaidImport ||= await import('https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.7.0/mermaid.esm.min.mjs')
              const mermaid = mermaidImport.default
              const darkMode = document.documentElement.getAttribute('saved-theme') === 'dark'
              mermaid.initialize({
                startOnLoad: false,
                securityLevel: 'loose',
                theme: darkMode ? 'dark' : 'default'
              })

              await mermaid.run({
                querySelector: '.mermaid'
              })
            }
          });
          </script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/contrib/copy-tex.min.js" type="application/javascript"></script><script src="../postscript.js" type="module"></script></html>